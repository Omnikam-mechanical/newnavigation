<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Navigation with YOLOv5 (ONNX)</title>
    <link rel="stylesheet" href="styles.css">
    <script defer src="script.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyA4MJSt9kk07UpIlSgXno4tsuziPf-bqcI&callback=initMap" async defer></script>
    <link rel="manifest" href="manifest.json">
</head>
<body>
    <header>
        <h1>AI Navigation with YOLOv5 (ONNX)</h1>
    </header>

    <section class="map-container">
        <h2>Navigation Map</h2>
        <input type="text" id="destination" placeholder="Enter destination">
        <button onclick="voiceInputDestination()">ðŸŽ¤ Voice Destination</button>
        <button onclick="startNavigation()">Start Navigation</button>
        <div id="map"></div>
    </section>

    <section class="camera-container">
        <h2>Obstacle Detection (YOLOv5 ONNX)</h2>
        <video id="video" autoplay playsinline></video>
        <canvas id="canvas"></canvas>
        <p id="status">Detecting...</p>
    </section>

    <script>
        async function initYOLOv5ONNX() {
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            const statusText = document.getElementById('status');

            const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
            video.srcObject = stream;

            const session = await ort.InferenceSession.create('https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.onnx');

            async function detectObjects() {
                const tensor = tf.browser.fromPixels(video).resizeNearestNeighbor([640, 640]).toFloat().div(tf.scalar(255)).expandDims(0);
                const results = await session.run({ images: tensor });

                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                const boxes = results['boxes'].data;
                const scores = results['scores'].data;
                const classes = results['classes'].data;

                for (let i = 0; i < scores.length; i++) {
                    if (scores[i] > 0.5) { // Confidence Threshold
                        const [x1, y1, x2, y2] = boxes.slice(i * 4, (i + 1) * 4);
                        const width = x2 - x1;
                        const height = y2 - y1;

                        ctx.beginPath();
                        ctx.rect(x1, y1, width, height);
                        ctx.lineWidth = 2;
                        ctx.strokeStyle = 'red';
                        ctx.stroke();
                        ctx.fillStyle = 'red';
                        ctx.fillText(`Object ${Math.round(scores[i] * 100)}%`, x1, y1 - 10);

                        statusText.innerText = `Warning! Obstacle detected.`;
                        speakText(`Warning! Obstacle detected.`);
                    }
                }

                requestAnimationFrame(detectObjects);
            }

            detectObjects();
        }

        async function initMap() {
            const map = new google.maps.Map(document.getElementById('map'), { zoom: 14 });
            if (navigator.geolocation) {
                navigator.geolocation.getCurrentPosition(position => {
                    map.setCenter({ lat: position.coords.latitude, lng: position.coords.longitude });
                });
            }
        }

        function voiceInputDestination() {
            speakText("Please say your destination.");
            const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = "en-US";
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                document.getElementById("destination").value = transcript;
                speakText(`Destination set to ${transcript}. Starting navigation.`);
                startNavigation();
            };
            recognition.start();
        }

        function startNavigation() {
            const destination = document.getElementById('destination').value;
            if (destination) {
                window.open(`https://www.google.com/maps/dir/?api=1&destination=${encodeURIComponent(destination)}`, '_blank');
            }
        }

        function speakText(message) {
            const speech = new SpeechSynthesisUtterance(message);
            speech.lang = 'en-US';
            window.speechSynthesis.speak(speech);
        }

        window.onload = initYOLOv5ONNX;
        
    if ("serviceWorker" in navigator) {
        window.addEventListener("load", () => {
            navigator.serviceWorker.register("./service-worker.js").then(() => {
                console.log("Service Worker Registered");
            });
        });
    }
</script>
    </script>
</body>
</html>
